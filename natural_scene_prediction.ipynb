{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import typing\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as effn\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "def prepare_pred_dataset_from_fps(list_of_fp : [list], BATCH_SIZE : int = 32):\n",
    "    \n",
    "    \"\"\"\n",
    "    [ Reads a list of image filepaths and preprocess them for the image classifer model.\n",
    "      Order of the list] of filepaths is preserved.]\n",
    "\n",
    "    Args:\n",
    "        list_of_fp ([list]): [list of image filepaths]\n",
    "        BATCH_SIZE (int): BATCH_SIZE for prediction.\n",
    "        Lower the batch size if run into OOM during prediction\n",
    "\n",
    "    Returns:\n",
    "        [Tensorflow Dataset]\n",
    "    \"\"\"    \n",
    " \n",
    "    def read_decode_img(img_fp : str):\n",
    "        # read, decode and preprocess single image filepath\n",
    "        img = tf.io.read_file(img_fp)\n",
    "        img = tf.io.decode_jpeg(img,try_recover_truncated=True)\n",
    "        img = tf.image.resize(img,[260,260])/255 # normalise pixel values\n",
    "        return img\n",
    "    \n",
    "    img_fp_ds = tf.data.Dataset.from_tensor_slices(list_of_fp)\n",
    "    img_ds = img_fp_ds.map(read_decode_img,num_parallel_calls=AUTO) #map processing function to all images\n",
    "    img_ds = img_ds.batch(BATCH_SIZE).prefetch(AUTO)\n",
    "    return img_ds\n",
    "\n",
    "def decode_prediction(pred_array,top_n = 5, thresohold = 0.5):\n",
    "    \n",
    "    \"\"\"[Decode n x 22 predicton array from the classifier model]\n",
    "\n",
    "    Args:\n",
    "        pred_array ([np.array]): [raw prediction array from model prediction]\n",
    "        \n",
    "        top_n (int, optional): \n",
    "        [top_n prediction of the multilabel branch, regardless the confidence level of individual prediction]. \n",
    "        Defaults to 5.\n",
    "        \n",
    "        thresohold (float, optional): [Thresohold of multilabel prediction]. Defaults to 0.5.\n",
    "    Returns:\n",
    "    [three list of decoded predictions]: \n",
    "    [Decoded predictions would return THREE lists in form of:\n",
    "    [threeclass_pred_n_prob_paired],[multilabel_pred_top_n], [multilabel_pred_over_threshold]\n",
    "    \"\"\"    \n",
    "    \n",
    "    def multilabel_over_threshold_predictions(multilabel_pred_array,thresohold):\n",
    "        # map labels to predictions > thresohold\n",
    "        idx_with_conf = np.where(multilabel_pred_array>thresohold)[0] # find the index of element > thresohold\n",
    "        pred_label = list(map(multilabel_class_index.get, idx_with_conf)) \n",
    "        label_prob = multilabel_pred_array[idx_with_conf]\n",
    "        return dict(sorted(list(zip(pred_label,np.round(label_prob,4))),key = lambda x: x[1])[::-1])  # sort by the prob of (label,prob) pair and reverse it\n",
    "    \n",
    "    def multilabel_top_n_predictions(multilabel_pred_array, top_n):\n",
    "        # map labels to top 5 prediction\n",
    "        sorted_top5_pred = multilabel_pred_array.argsort()[::-1][:top_n]\n",
    "        pred_label = list(map(multilabel_class_index.get, sorted_top5_pred))\n",
    "        label_prob = multilabel_pred_array[sorted_top5_pred]\n",
    "        return dict(list(zip(pred_label,np.round(label_prob,4))))\n",
    "\n",
    "    threeclass_class_index = {0:'nature',1:'indoor',2:'ambiguous'} \n",
    "    multilabel_class_index = {0: 'indoor',\n",
    "                             1: 'outdoor, natural',\n",
    "                             2: 'outdoor, man-made',\n",
    "                             3: 'shopping and dining',\n",
    "                             4: 'workplace (office building, factory, lab, etc.)',\n",
    "                             5: 'home or hotel',\n",
    "                             6: 'transportation (vehicle interiors, stations, etc.)',\n",
    "                             7: 'sports and leisure',\n",
    "                             8: 'cultural (art, education, religion, millitary, law, politics, etc.)',\n",
    "                             9: 'water, ice, snow',\n",
    "                             10: 'mountains, hills, desert, sky',\n",
    "                             11: 'forest, field, jungle',\n",
    "                             12: 'man-made elements',\n",
    "                             13: 'transportation (roads, parking, bridges, boats, airports, etc.)',\n",
    "                             14: 'cultural or historical building/place (millitary, religious)',\n",
    "                             15: 'sports fields, parks, leisure spaces',\n",
    "                             16: 'industrial and construction',\n",
    "                             17: 'houses, cabins, gardens, and farms',\n",
    "                             18: 'commercial buildings, shops, markets, cities, and towns'}\n",
    "    \n",
    "    # decode three class classifier\n",
    "    threeclass_pred = np.array([p[:3]for p in pred_vector]) # first 3 element = predicion of the 3 class classifier\n",
    "    threeclass_pred_argmax = threeclass_pred.argmax(axis=-1) # take the highest probability of 3 class as predicted class\n",
    "    threeclass_pred_label = list(map(threeclass_class_index.get,threeclass_pred_argmax)) # map class index to label\n",
    "    threeclass_pred_prob = [threeclass_pred[i][threeclass_pred_argmax[i]] for i in range(len(threeclass_pred_argmax))] # retrieve the probability of the \n",
    "    threeclass_pred_n_prob_paired = list(zip(threeclass_pred_label,threeclass_pred_prob)) #a pair of predicted label and its corresponding probability \n",
    "    \n",
    "    # decode multilabel class classifier\n",
    "    multilabel_pred = np.array([p[3:]for p in pred_vector]) # forth to nineteenth element as 19 classes multilabel\n",
    "    multilabel_pred_over_threshold = [multilabel_over_threshold_predictions(p,thresohold) for p in multilabel_pred] # multilabel predictions over threshold (0.5)\n",
    "    multilabel_pred_top_n = [multilabel_top_n_predictions(p,top_n) for p in multilabel_pred] # top n multilabel predictions \n",
    "    \n",
    "    return threeclass_pred_n_prob_paired,multilabel_pred_top_n, multilabel_pred_over_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_fps = [...,...]\n",
    "model_path = 'model_path'\n",
    "pred_ds = prepare_pred_dataset_from_fps(image_fps)\n",
    "scenery_model = tf.keras.models.load_model(model_path)\n",
    "pred_vector = scenery_model.predict(pred_ds,verbose=1) # the prediction vector is a n x 22 array, n as in number of images predicted, 22 as 3class + 19 classes multilabel\n",
    "pred1,pred2,pred3 = decode_prediction(pred_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or import predictor.py as module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scene_classifier\n",
    "pred1,pred,pred3 = scene_classifier.run_classifier(img_fps,model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}